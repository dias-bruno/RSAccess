---
title: "Identifying spatial patterns the Greater Golden Horseshoe area, Ontario, Canada"
author: "Bruno Dias dos Santos"
date: "`r Sys.Date()`"
output: html_document
---

## Introduction

This notebook is a component of the GEO712 course's final project at the School of Earth, Environment & Society of McMaster University. The main objective of the final project is to analyze and compare job accessibility levels across different spatial patterns, focusing on the Greater Golden Horseshoe area (GGH) in Ontario, Canada.

Within this notebook, we present a methodology to perform a Principal Component Analysis (PCA) and identify clusters through an unsupervised classification. The input files for this notebook include:

-   Hexagonal grid\_(grid_with_all_attributes.shp.shp)\_: A cell grid comprised of hexagons with an area of 500 mÂ² with all attributes, obtained after running the notebook *1a_features_extraction.qmd*.

-   Local Municipality Boundaries: Shapefile defining the study area's boundaries.

The output from this notebook includes shapefiles containing the features and the final classification in the cell grid.

## R Markdown

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load R libraries used in the notebook:

```{r}
library(sf)  # To read shapefiles *only*
library(ggplot2) # To plot maps *only*
library(here) # To insert the correct folder to save the pictures in 
```

Reading the cell grid and creating a sf DataFrame.

```{r}
cell_grid <- st_read("vectors\\output\\grid_with_all_attributes.shp")
```

Visualizing the grip in a map format:

```{r}
plot(st_geometry(cell_grid), axes = TRUE)
```

Visualizing the first five rows of the dataset:

```{r}
head(cell_grid,5)
```

Obtaining the name of the columns of the dataset:

```{r}
names(cell_grid)
```

Summarizing statistics of the data:

```{r}
summary(cell_grid)
```

Plotting a map of the data set by the variable "BP_mean", which means the average value of the "Built-up area" identified in the satellite images within the cell.

```{r}
plot(st_geometry(cell_grid), col = cell_grid$BP_mean, axes = TRUE, border = NA, main = "Mean of Built-up area")
```

The R built-in functions make difficult to visualize the difference of the variable between the cells. Because of this, we will use the ggplot library to plot a new map.

```{r}
ggplot() +
  geom_sf(data = cell_grid, aes(fill = BP_mean), color = NA) + 
  theme_minimal() 
```

Now we can see the differences in the built-up area within the study area.

Checking the total number of rows in the dataset.

```{r}
nrow(cell_grid)
```

Excluding possible missing values and rechecking the total number of rows.

```{r}
cell_grid <- na.omit(cell_grid)
nrow(cell_grid)
```

Plotting a histogram of the variable "BP_mean".

```{r}
hist(as.numeric(unlist(cell_grid["BP_mean"])), xlab = "Mean of built-up area", ylab = "Frequency", main = "Histogram of BP_mean")
```

Understanding intraurban differences is crucial for comprehending variations in accessibility levels. With the dataset at hand, we selected cells based on a threshold value for the presence of built-up areas. Hexagons with less than 10% of the sum of residential and commercial buildings were excluded from the analysis. This criterion was implemented to enhance the clustering process. Without this restriction, the clustering algorithm tended to create numerous clusters outside the urban area, without showing the intraurban differences.

Now, plotting a histogram of the filtered data.

```{r}
hist(cell_grid[(cell_grid$RES + cell_grid$COM) >= 0.1, ]$BP_mean, xlab = "Mean of built-up area", ylab = "Frequency", main = "Histogram of BP_mean of the selected cells")
```

Creating a new dataset with the selected data.

```{r}
subset <- as.data.frame(cell_grid[(cell_grid$RES + cell_grid$COM) >= 0.1, ])
```

Creating a dataframe, excluding the variables 'id' and 'geometry' to perform the PCA Analysis.

```{r}
df <- subset[,2:(length(subset)-1)]
```

Visualization of the correlation matrix of the variables related to the built-up area.

```{r}
corr_mv <- cor(df[,1:7])
corr_mv
```

We can see that some variables have a high correlation. For instance, BP_mean and BP_std have a correlation of around 0.87. In fact, the entire data set has variables with a high level of linear correlation. For this reason, we will apply a PCA analysis to reduce the dimensionality of the data.

## Principal Component Analysis

Creating the PCA, normalizing the data.

```{r}
#pca_out <- prcomp(df, center = TRUE, scale = TRUE)
```

There is an error in our data set, because one (or more) of our variables has a constant value, making it impossible to scale the z score. The code above will remove columns with constant values:

```{r}
remove <- c()

# Evaluating if the variance of each column is equal to zero
for(i in 1:length(names(df))){
  if(var(df[,i])==0){
    remove <- append(remove, i)
  }
}

# Removing columns with constant value of the dataset
df <- subset(df, select = -remove)
```

Conting the number of variables of the new dataset.

```{r}
ncol(df)
```

visualizing the index of the column that has constant value.

```{r}
remove
```

Performing a new PCA analysis.

```{r}
pca_out <- prcomp(df, center = TRUE, scale = TRUE)
```

Visualizing the summary of our PCA.

```{r}
summary(pca_out)
```

We can see that the first component explains 35% of the variability in our data; the second component explains 9%; and so on. The first thirty-five components accumulate 90% of the variability of the original dataset.

Plotting a graph to visualizing the cumulative proportion of variance.

```{r}
# Calculating the proportion of variance explained by each principal component
var <- pca_out$sdev^2 / sum(pca_out$sdev^2)

# Converting variance to percentages
var <- var * 100

# Creating a variable to hold the cumulative sum of variance
var_sum <- var

# Calculating the cumulative sum of variance
for (i in 2:length(var_sum)) {
var_sum[i] <- var_sum[i] + var_sum[i - 1]
}

# Creating a plot of principal component variances
plot(c(1:length(var)), var, xlab="Principal component",ylab="Variance explained", main = "Principal component variances", col = "blue", type = "b",ylim = c(0, max(var,var_sum)))

# Adding a line plot for the cumulative sum of variance
lines(c(1:length(var)), var_sum, col = "red")

# Adding a legend
legend("right", legend=c("Sum of variance", "Variance"),
col=c("red", "blue"), lty=1:2, cex=0.8,
text.font=3, box.lty=0, bg=)
```

Plotting a biplot graph.

```{r}
biplot(pca_out)
```

Due to the large number of variables, it is difficult to see a pattern in the biplot above.

Selecting the components where the cumulative variation of the original dataset is 90%.

```{r}
principalDf <- pca_out$x[,1:35]
```

Obtaining the loadings of the selected components.

```{r}
loadings <- as.data.frame(pca_out$rotation[,1:35])
```

Visualizing the top 3 absolute loadings for each PC.

```{r}
set.seed(51)

get_top_loadings <- function(pc_vector) {
  top_indices <- order(abs(pc_vector), decreasing = TRUE)[1:3]
  return(top_indices)
}

top_indices_list <- apply(loadings[,1:4], 2, get_top_loadings)
```

Visualizing the indexes of the variables with the highest loadings in the first four principal components.

```{r}
top_indices_list
```

Selecting the 3 principal loadings for the first four principal components.

```{r}
merged_column <- unique(c(top_indices_list))
round(loadings[merged_column,1:4],3)
```

Across all components, variables related to neighbor relations demonstrated the most substantial loadings. Component 1 exhibits higher absolute loadings in the neighbor mean of built-up type variables, predominantly associated with more densely built-up areas in the study area; Component 2 displays higher absolute loadings in variables related to the fraction of water on neighboring cells, indicating a correlation with waterfront areas; Component 3 focuses on the presence of built-up areas and residential use in neighboring cells; and Component 4 correlates with the presence of trees in neighboring cells.

## Clustering Analysis

Creating the clustering model. After several experiments and visual analyses, we settled on six final clusters, considering the best trade-off between identifying meaningful clusters and their quantity.

```{r}
set.seed(51)
clustering <- kmeans(principalDf, centers=6, iter.max = 500, algorithm = "Lloyd")
```

Visualizing the amount of features in each group.

```{r}
clustering$size
```

Adding the cluster classification to the PC dataframe

```{r}
principalDf <- as.data.frame(principalDf)
principalDf$Cluster <- clustering$cluster
principalDf$id <- subset$id
```

```{r}
principalDf
```

Bringing these new variables to the grid dataset.

```{r}
grid_with_all_attributes <- merge(cell_grid, principalDf, by.x = 'id', by.y = 'id', all.x=TRUE)
```

Transforming this dataset into a sf dataset.

```{r}
grid_with_all_attributes <- st_as_sf(grid_with_all_attributes, crs = st_crs(cell_grid))
```

Creating a dataset with the classification.

```{r}
grid_classified <- grid_with_all_attributes[,c("id","Cluster")]
```

Plotting a map of the spatial patterns.

```{r}
boundaries <- sf::st_read("vectors//boundaries//tts06_pd_83.shp")

custom_colors <- c("#d6395e", "#33a02c", "#b0b0b0", "#ffb400", "#1f78f2", "#72df88")

map <- ggplot() +
  geom_sf(data = grid_classified[!(is.na(grid_classified$Cluster)),], aes(fill = as.factor(Cluster)), color = NA) +
  geom_sf(data = boundaries, color = "#4a4a4a", fill = NA) + 
  labs(fill = "Cluster") +
  scale_fill_manual(values = custom_colors) +
  theme_minimal()

map
```

Selection of a variable to evaluate the difference between the clusters.

```{r}
par(mfrow = c(2, 4))

# Boxplot 1: Built-up Mean
boxplot(BP_mean ~ Cluster, data = grid_with_all_attributes[!(is.na(grid_with_all_attributes$Cluster)),], main = "Built-up Mean", outline = FALSE)

# Boxplot 2: Tree Mean
boxplot(TR_mean ~ Cluster, data = grid_with_all_attributes[!(is.na(grid_with_all_attributes$Cluster)),], main = "Tree Mean", outline = FALSE)

# Boxplot 3: % Residential
boxplot(RES ~ Cluster, data = grid_with_all_attributes[!(is.na(grid_with_all_attributes$Cluster)),], main = "% Residential", outline = FALSE)

# Boxplot 4: "% Commerce"
boxplot(COM ~ Cluster, data = grid_with_all_attributes[!(is.na(grid_with_all_attributes$Cluster)),],main = "% Commerce", outline = FALSE)

# Boxplot 5: Grass Mean
boxplot(GR_mean ~ Cluster, data = grid_with_all_attributes[!(is.na(grid_with_all_attributes$Cluster)),], main = "Grass Mean", outline = FALSE)

# Boxplot 6: Crop Mean
boxplot(CR_mean ~ Cluster, data = grid_with_all_attributes[!(is.na(grid_with_all_attributes$Cluster)),], main = "Crop Mean", outline = FALSE)

# Boxplot 7: Water Mean
boxplot(DInRo ~ Cluster, data = grid_with_all_attributes[!(is.na(grid_with_all_attributes$Cluster)),], main = "Water Mean", outline = FALSE)

# Boxplot 8: wa_ac_emp
boxplot(DInBP ~ Cluster, data = grid_with_all_attributes[!(is.na(grid_with_all_attributes$Cluster)),], main = "Intersections by BP area", outline = FALSE)

par(mfrow = c(1, 1))
```

## Data export

Saving the cluster's figure.

```{r}
ggsave(here::here("figures", "spatial_patterns_map.png"), map, width = 10, height = 8, units = "cm")
```

Exporting the classification dataset.

```{r}
st_write(grid_classified, "vectors\\output\\grid_classified.shp", append=FALSE)
```

Dataset export with all attributes, selected principal components and clustering result.

```{r}
st_write(grid_with_all_attributes, "vectors\\output\\grid_with_attributes_35pcas_cluster.shp", append=FALSE)
```
