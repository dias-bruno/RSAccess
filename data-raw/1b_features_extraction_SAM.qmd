---
title: "Feature extraction and dataset creation"
author: "Bruno D. dos Santos"
format: html
jupyter: python3
execute: 
  cache: true
---

## Introduction

This notebook is a component of the GEO712 course's final project at the School of Earth, Environment & Society of McMaster University. The main objective of the final project is to analyze and compare job accessibility levels across different spatial patterns, focusing on the Greater Golden Horseshoe area (GGH) in Ontario, Canada.

Within this notebook, we present a methodology for transferring Spatial Access Measures onto a hexagonal grid. The input files for this notebook include:
-   Hexagonal grid _(hexagon_500m2.shp)_: A cell grid comprised of hexagons with an area of 500 m². Remote sensing imagery and road network data attributes will be transferred to this grid. This data was obtained with QGIS's create grid function.
-   Spatial Access Measures (SAM) _(acs_walking.csv, acs_cycling.csv, acs_public_transit_offpeak.csv,  acs_public_transit_peak.csv)_: A national dataset in CSV format that measures accessibility to various opportunities, considering different modes of transport. The SAM database computed for each dissemination block accessibility score in a scale of zero to one (0 - 1), where zero means the least and one means maximum accessibility. For this work, we used only the accessibility measures for employments based on the transportation modes: access via public transit during peak hours, access via public transit during off-peak hours, access via cycling and access via walking.

The output from this notebook includes shapefiles containing the features in the cell grid.

## Quarto

Load python libraries used in the notebook:
```{python}
import geopandas as gpd
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from geopandas.tools import sjoin
import rasterio
from rasterstats import zonal_stats
import shapely
from shapely.geometry import Polygon, LineString
```

Reading the cell grid and creating a GeoDataFrame. We generate this hexagonal grid using QGIS software, indicating a value of 0.8774 meters to the principal diagonal, resulting in a hexagon with 500 m².
```{python reading-grid}
grid = gpd.read_file("vectors\\input\\hexagon_500m2.shp", geometry = 'geometry')
```

Creating a spatial index for the hexagonal grid to expedite spatial relations between geometries:
```{python spatial-index-grid}
grid.sindex
```

### Remote sensing attributes

Setting the satellite images' path: 
```{python rs-path}
raster_list = {'BP':'GHS_BUILT_S_E2018_epsg26917.tif', 'HE': 'GHS_BUILT_H_E2020_epsg26917.tif', 'VO': 'GHS_BUILT_V_E2020_epsg26917.tif', 'CL': 'GHS_BUILT_C_FUN_E2018_epsg26917.tif',
            'TR':'PROBAV_LC100_2018_Tree_epsg26917.tif',
            'CR':'PROBAV_LC100_2018_Crops_epsg26917.tif',
            'GR':'PROBAV_LC100_2018_Grass_epsg26917.tif',
            'WA':'PROBAV_LC100_2018_Water_epsg26917.tif',
            'SH':'PROBAV_LC100_2018_Shrub_epsg26917.tif'}
```

Extracting attributes from the satellite images to the hexagonal grid:
```{python extract-rs-attributes}

new_grid_rs = grid

for key in raster_list.keys():
    path_image = 'rasters' + '\\' + input + '\\' + raster_list[key]
   
    if key in ['BP', 'HE', 'VO', 'TR', 'GR','CR', 'WA', 'SH']:
        zs = zonal_stats(grid, path_image, stats=['min', 'max', 'mean', 'std', 'median', 'majority', 'sum'])
        df = pd.DataFrame(zs).fillna(0)
        df.columns = key + '_' + df.columns
        new_grid_rs = new_grid_rs.merge(df, left_index=True, right_index=True)    
       
    elif key in ['CL']:
        
        count = zonal_stats(grid, path_image, stats=['count'])

        if  key == 'CL':
            cmap = {0: 'NRC', 1: 'RES', 2:'COM'}
            zs = zonal_stats(grid, path_image, categorical = True, category_map=cmap)
            df = pd.DataFrame(zs).fillna(0)
            total = df['NRC'] + df['RES'] + df['COM']
            df['NRC'] = df['NRC']/total
            df['RES'] = df['RES']/total
            df['COM'] = df['COM']/total
            new_grid_rs = new_grid_rs.merge(df, left_index=True, right_index=True)
```

Saving the data so we can continue from this part next time.
```{python save-rs-data}
new_grid_rs.to_file("vectors\\output\\rs_attributes.shp")
# new_grid_rs = gpd.read_file("vectors\\output\\rs_attributes.shp")
```


### Road network attributes

Reading the road network shapefile and creating a GeoDataFrame.
```{python read-road-network}
roads = gpd.read_file("vectors\\input\\roads_osm_cl.shp")
```

Creating a spatial index for the road network to expedite spatial relations between geometries:
```{python road-network-spatial-index}
roads.sindex
```

Extracting attributes from the road network to the hexagonal grid:
```{python extract-road-network-attributes}
explode = gpd.overlay(grid, roads, how='intersection', keep_geom_type=False).explode()
explode.index.names = ['level_1', 'level_2']
explode['SI'] = 0.0

for (level_1, level_2), group in explode.groupby(level=['level_1', 'level_2']):
        try:
            start_pt = LineString(explode['geometry'][level_1][level_2]).coords[0]
            end_pt = LineString(explode['geometry'][level_1][level_2]).coords[-1]
            straight_line = LineString((start_pt, end_pt))
            line = LineString(explode['geometry'][level_1][level_2])

            if straight_line.length == 0:
                sinuosity = 1
            else:
                sinuosity = line.length / (straight_line.length + 0.01)

            explode['SI'][level_1][level_2] = sinuosity 
        
        except:
                explode['SI'][level_1][level_2] = explode['SI'][level_1][level_2 - 1]
        
explode['LE'] = explode['geometry'].length

attributes_to_transfer = ['SI', 'LE']

weighted_values = pd.DataFrame()

for attribute in attributes_to_transfer:
    explode[f'{attribute}_weighted'] = explode[attribute] * explode['LE']

    sum_weighted = explode.groupby('id')[f'{attribute}_weighted'].sum()

    sum_length = explode.groupby('id')['LE'].sum()

    weighted_values[attribute + '_mean'] = sum_weighted / sum_length
    weighted_values[attribute + '_sum'] = explode.groupby('id')[attribute].sum()
    weighted_values[attribute + '_min'] = explode.groupby('id')[attribute].min()
    weighted_values[attribute + '_max'] = explode.groupby('id')[attribute].max()
    weighted_values[attribute + '_std'] = explode.groupby('id')[attribute].std()
    
weighted_values['NRo'] = explode.groupby('id')['LE'].count()

# Add the weighted columns to the original DataFrame 
new_grid_roads = pd.merge(grid, weighted_values, left_on='id', right_index=True, how='left').fillna(0)
```

Saving the data so we can continue from this part next time.
```{python save-roads-attributes}
new_grid_roads.to_file("vectors\\output\\roads_attributes.shp")
#new_grid_roads = gpd.read_file("vectors\\output\\roads_attributes.shp")
```

Reading the roads intersections shapefile and creating a GeoDataFrame with spatial. After this, we'll do a spatial join between the intersection roads points and the hexagonal grid.
```{python}
intersections = gpd.read_file("vectors\\input\\intersections_points.shp")
intersections.sindex
intersections['NIn'] = 0
it = pd.DataFrame(sjoin(grid, intersections, how="left", op='intersects').groupby('id')['NIn'].count())
del intersections
```

Bringing road attributes to the point intersections file to create new attributes.
```{python}
it['id'] = it.index
it.index.names = ['']
it = it.merge(new_grid_roads[['id','NRo']], left_on='id', right_on ='id', how='left').merge(new_grid_rs[['id','BP_sum','geometry']] ,left_on='id', right_on ='id', how='left')
it = gpd.GeoDataFrame(it)
```

Creating new variables for the intersection file.
```{python}
it['DInBP'] = it['NIn'] / (it['BP_sum'] + 0.1)
it['DInRo'] = it['NIn']  / it['NRo']
```

Saving the data so we can continue from this part next time.
```{python}
it.to_file("vectors\\output\\grade_with_intersections_points.shp")
#it = gpd.read_file("vectors\\output\\grade_with_intersections_points.shp")
```

Reorganizing the intersection GeoDataFrame columns. 
```{python}
it = it[['id','NIn','NRo', 'BP_sum', 'DInBP','DInRo', 'geometry']]
```

Creating a new GeoDataFrame with all attributes.
```{python}
grid_attributes = new_grid_rs.iloc[:,:-1].merge(new_grid_roads.iloc[:,:-1].merge(it[['id','NIn','DInBP','DInRo','geometry']], left_on = 'id', right_on = 'id', how="left"), left_on = 'id', right_on = 'id', how = 'left')
```

Filling missing values with 0.
```{python}
grid_attributes = grid_attributes.fillna(0)
```

### Neighboors attributes

Reading the grid distance matrix. This matrix was generated using QGIS software, indicating the six nearest target cells for each hexagon. 
```{python}
matrix = pd.read_csv("csvs\\input\\grid_distance_matrix.csv")
```

Merging the distance matrix with the grid GeoDataFrame with attributes.
```{python}
id_origem = 'InputID'
id_destin = 'TargetID'
data = matrix.merge(grid_attributes, left_on =id_destin, right_on='id')
```

Obtaining the neighbors' means for each grid attribute.
```{python}
NM = data.groupby(id_origem, sort=True).mean()
NM.insert(0,'InputID',NM.index)
NM['id'] = NM[id_origem]
NM.index.names = ['']
NM = NM.reset_index()
NM = NM[new_grid_rs.iloc[:,:-1].columns]
NM
```

Obtaining the normalized difference neighbors' means for each grid attribute.
```{python}
DNM = (pd.DataFrame(new_grid_rs.iloc[:,:-1]) - pd.DataFrame(NM))/(pd.DataFrame(new_grid_rs.iloc[:,:-1]) + pd.DataFrame(NM))
DNM = DNM.fillna(0)
DNM['id'] = NM['id']
DNM
```

Renaming the GeoDataFrame columns.
```{python}
DNM.columns = 'DNM_' + DNM.columns
NM.columns = 'NM_' + NM.columns
```

Merging GeoDataFrames: 
```{python}
DNM = DNM.merge(grid, right_on = 'id', left_on = 'DNM_id', how = 'left')
DNM = DNM.drop('id', axis = 1)
DNM
```

Creating a GeoDataFrame with all attributes:
```{python}
final_grid = grid_attributes.iloc[:,:-1].merge(NM, left_on = 'id', right_on = 'NM_id', how = 'left').merge(DNM, left_on = 'id', right_on = 'DNM_id', how = 'left')
final_grid = final_grid.drop(['NM_id','DNM_id'], axis = 1)
final_grid
```

Saving the final GeoDataFrame:
```{python}
gpd.GeoDataFrame(final_grid).to_file("vectors\\output\\grid_with_all_attributes.shp")
# final_grid = gpd.read_file("vectors\\output\\grid_with_all_attributes.shp")
```

