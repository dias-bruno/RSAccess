{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Feature extraction and dataset creation\n",
        "author: Bruno D. dos Santos\n",
        "format: pdf\n",
        "execute:\n",
        "  echo: false\n",
        "---"
      ],
      "id": "8bd3c9f0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n",
        "\n",
        "This notebook is a component of the GEO712 course's final project at the School of Earth, Environment & Society of McMaster University. The main objective of the final project is to analyze and compare job accessibility levels across different spatial patterns, focusing on the Greater Golden Horseshoe area (GGH) in Ontario, Canada.\n",
        "\n",
        "Within this notebook, we present a methodology for extracting features from satellite imagery and road network data and transferring them onto a hexagonal grid. The input files for this notebook include:\n",
        "-   Hexagonal grid _(hexagon_500m2.shp)_: A cell grid comprised of hexagons with an area of 500 m². Remote sensing imagery and road network data attributes will be transferred to this grid.\n",
        "-   Road network _(roads_osm_cl.shp)_: A shapefile representing the road network, which will be used to create variables and transfer them to the hexagonal grid.\n",
        "-   Road intersections _(intersections_points.shp)_: A point shapefile indicating road intersections. This file will be used to create variables and transfer them to the hexagonal grid.\n",
        "-   Distance matrix _(grid_distance_matrix.csv)_: A CSV-formatted table containing a distance matrix for the cell grid. \n",
        "-   Spatial Access Measures _(SAM, INCLUDE HERE)_: A national dataset in CSV format that measures accessibility to various opportunities, considering different modes of transport.\n",
        "-   Dissemination block _(INCLUDE HERE)_: The spatial unit used by the SAM project to compute accessibility measures.\n",
        "\n",
        "The output from this notebook includes shapefiles containing the features in the cell grid.\n",
        "\n",
        "## Quarto\n",
        "\n",
        "Load python libraries used in the notebook:"
      ],
      "id": "d148564f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from geopandas.tools import sjoin\n",
        "import rasterio\n",
        "from rasterstats import zonal_stats\n",
        "import shapely\n",
        "from shapely.geometry import Polygon, LineString"
      ],
      "id": "e4e5f9d2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reading the cell grid and creating a GeoDataFrame. We generate this hexagonal grid using QGIS software, indicating a value of 0.8774 meters to the principal diagonal, resulting in a hexagon with 500 m²."
      ],
      "id": "52508c4d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid = gpd.read_file(\"vectors\\\\hexagon_500m2.shp\", geometry = 'geometry')"
      ],
      "id": "6f458494",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating a spatial index for the hexagonal grid to expedite spatial relations between geometries:"
      ],
      "id": "cdd56975"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid.sindex"
      ],
      "id": "7af0e463",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Remote sensing attributes\n",
        "\n",
        "Setting the satellite images' path: "
      ],
      "id": "fe8300c3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "raster_list = {'BP':'GHS_BUILT_S_E2018_epsg26917.tif', 'HE': 'GHS_BUILT_H_E2020_epsg26917.tif', 'VO': 'GHS_BUILT_V_E2020_epsg26917.tif', 'CL': 'GHS_BUILT_C_FUN_E2018_epsg26917.tif',\n",
        "            'TR':'PROBAV_LC100_2018_Tree_epsg26917.tif',\n",
        "            'CR':'PROBAV_LC100_2018_Crops_epsg26917.tif',\n",
        "            'GR':'PROBAV_LC100_2018_Grass_epsg26917.tif',\n",
        "            'WA':'PROBAV_LC100_2018_Water_epsg26917.tif',\n",
        "            'SH':'PROBAV_LC100_2018_Shrub_epsg26917.tif'}"
      ],
      "id": "9329836d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extracting attributes from the satellite images to the hexagonal grid:"
      ],
      "id": "b35eaf5f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "new_grid_rs = grid\n",
        "\n",
        "for key in raster_list.keys():\n",
        "    path_image = 'rasters' + '\\\\' + raster_list[key]\n",
        "   \n",
        "    if key in ['BP', 'HE', 'VO', 'TR', 'GR','CR', 'WA', 'SH']:\n",
        "        zs = zonal_stats(grid, path_image, stats=['min', 'max', 'mean', 'std', 'median', 'majority', 'sum'])\n",
        "        df = pd.DataFrame(zs).fillna(0)\n",
        "        df.columns = key + '_' + df.columns\n",
        "        new_grid_rs = new_grid_rs.merge(df, left_index=True, right_index=True)    \n",
        "       \n",
        "    elif key in ['CL']:\n",
        "        \n",
        "        count = zonal_stats(grid, path_image, stats=['count'])\n",
        "\n",
        "        if  key == 'CL':\n",
        "            cmap = {0: 'NRC', 1: 'RES', 2:'COM'}\n",
        "            zs = zonal_stats(grid, path_image, categorical = True, category_map=cmap)\n",
        "            df = pd.DataFrame(zs).fillna(0)\n",
        "            total = df['NRC'] + df['RES'] + df['COM']\n",
        "            df['NRC'] = df['NRC']/total\n",
        "            df['RES'] = df['RES']/total\n",
        "            df['COM'] = df['COM']/total\n",
        "            new_grid_rs = new_grid_rs.merge(df, left_index=True, right_index=True)"
      ],
      "id": "5d7ad1cd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saving the data so we can continue from this part next time."
      ],
      "id": "2788a86a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "new_grid_rs.to_file(\"vectors\\\\rs_attributes.shp\")\n",
        "# new_grid_rs = gpd.read_file(\"vectors\\\\rs_attributes.shp\")"
      ],
      "id": "d6ceadd5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Road network attributes\n",
        "\n",
        "Reading the road network shapefile and creating a GeoDataFrame."
      ],
      "id": "209a8f2f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "roads = gpd.read_file(\"vectors\\\\roads_osm_cl.shp\")"
      ],
      "id": "7eb65c6d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating a spatial index for the road network to expedite spatial relations between geometries:"
      ],
      "id": "5785b94a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "roads.sindex"
      ],
      "id": "d52e45e7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extracting attributes from the road network to the hexagonal grid:"
      ],
      "id": "b40f06f7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "explode = gpd.overlay(grid, roads, how='intersection', keep_geom_type=False).explode()\n",
        "explode.index.names = ['level_1', 'level_2']\n",
        "explode['SI'] = 0.0\n",
        "\n",
        "for (level_1, level_2), group in explode.groupby(level=['level_1', 'level_2']):\n",
        "        try:\n",
        "            start_pt = LineString(explode['geometry'][level_1][level_2]).coords[0]\n",
        "            end_pt = LineString(explode['geometry'][level_1][level_2]).coords[-1]\n",
        "            straight_line = LineString((start_pt, end_pt))\n",
        "            line = LineString(explode['geometry'][level_1][level_2])\n",
        "\n",
        "            if straight_line.length == 0:\n",
        "                sinuosity = 1\n",
        "            else:\n",
        "                sinuosity = line.length / (straight_line.length + 0.01)\n",
        "\n",
        "            explode['SI'][level_1][level_2] = sinuosity \n",
        "        \n",
        "        except:\n",
        "                explode['SI'][level_1][level_2] = explode['SI'][level_1][level_2 - 1]\n",
        "        \n",
        "explode['LE'] = explode['geometry'].length\n",
        "\n",
        "# Lista de atributos a serem transferidos\n",
        "attributes_to_transfer = ['SI', 'LE']\n",
        "\n",
        "# DataFrame para armazenar os resultados ponderados\n",
        "weighted_values = pd.DataFrame()\n",
        "\n",
        "for attribute in attributes_to_transfer:\n",
        "    # Criar coluna ponderada para o atributo atual\n",
        "    explode[f'{attribute}_weighted'] = explode[attribute] * explode['LE']\n",
        "\n",
        "    # Calcular a soma ponderada por 'id'\n",
        "    sum_weighted = explode.groupby('id')[f'{attribute}_weighted'].sum()\n",
        "\n",
        "    # Calcular a soma total dos comprimentos por 'id'\n",
        "    sum_length = explode.groupby('id')['LE'].sum()\n",
        "\n",
        "    # Calcular a média ponderada e atribuir ao DataFrame final\n",
        "    weighted_values[attribute + '_mean'] = sum_weighted / sum_length\n",
        "    weighted_values[attribute + '_sum'] = explode.groupby('id')[attribute].sum()\n",
        "    weighted_values[attribute + '_min'] = explode.groupby('id')[attribute].min()\n",
        "    weighted_values[attribute + '_max'] = explode.groupby('id')[attribute].max()\n",
        "    weighted_values[attribute + '_std'] = explode.groupby('id')[attribute].std()\n",
        "    \n",
        "weighted_values['NRo'] = explode.groupby('id')['LE'].count()\n",
        "\n",
        "# Adicionar as colunas ponderadas ao DataFrame original (s_grid)\n",
        "new_grid_roads = pd.merge(grid, weighted_values, left_on='id', right_index=True, how='left').fillna(0)"
      ],
      "id": "1939e5bc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saving the data so we can continue from this part next time."
      ],
      "id": "48b22606"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "new_grid_roads.to_file(\"vectors/roads_attributes.shp\")\n",
        "#new_grid_roads = gpd.read_file(\"vectors/roads_attributes.shp\")"
      ],
      "id": "ca69739f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reading the roads intersections shapefile and creating a GeoDataFrame with spatial. After this, we'll do a spatial join between the intersection roads points and the hexagonal grid."
      ],
      "id": "3808dd66"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "intersections = gpd.read_file(\"vectors\\\\intersections_points.shp\")\n",
        "intersections.sindex\n",
        "intersections['NIn'] = 0\n",
        "it = pd.DataFrame(sjoin(grid, intersections, how=\"left\", op='intersects').groupby('id')['NIn'].count())\n",
        "del intersections"
      ],
      "id": "4b694962",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bringing road attributes to the point intersections file to create new attributes."
      ],
      "id": "a7b74abd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "it['id'] = it.index\n",
        "it.index.names = ['']\n",
        "it = it.merge(new_grid_roads[['id','NRo']], left_on='id', right_on ='id', how='left').merge(new_grid_rs[['id','BP_sum','geometry']] ,left_on='id', right_on ='id', how='left')\n",
        "it = gpd.GeoDataFrame(it)"
      ],
      "id": "c25e526e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating new variables for the intersection file."
      ],
      "id": "6549e5a6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "it['DInBP'] = it['NIn'] / (it['BP_sum'] + 0.1)\n",
        "it['DInRo'] = it['NIn']  / it['NRo']"
      ],
      "id": "24e41748",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saving the data so we can continue from this part next time."
      ],
      "id": "7cc5de6c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "it.to_file(\"vectors/grade_with_intersections_points.shp\")\n",
        "# it = gpd.read_file(\"vectors/grade_with_intersections_points.shp\")"
      ],
      "id": "e2264cd4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reorganizing the intersection GeoDataFrame columns. "
      ],
      "id": "b049a130"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "it = it[['id','NIn','NRo', 'BP_sum', 'DInBP','DInRo', 'geometry']]"
      ],
      "id": "4b28e15f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating a new GeoDataFrame with all attributes."
      ],
      "id": "d218d3b1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid_attributes = new_grid_rs.iloc[:,:-1].merge(new_grid_roads.iloc[:,:-1].merge(it[['id','NIn','DInBP','DInRo','geometry']], left_on = 'id', right_on = 'id', how=\"left\"), left_on = 'id', right_on = 'id', how = 'left')"
      ],
      "id": "d7ada6c6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filling missing values with 0."
      ],
      "id": "66c85cc9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid_attributes = grid_attributes.fillna(0)"
      ],
      "id": "eb19c451",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Neighboors attributes\n",
        "\n",
        "Reading the grid distance matrix. This matrix was generated using QGIS software, indicating the six nearest target cells for each hexagon. "
      ],
      "id": "2d3a8138"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "matrix = pd.read_csv(\"sheets\\grid_distance_matrix.csv\")"
      ],
      "id": "5fcbd636",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merging the distance matrix with the grid GeoDataFrame with attributes."
      ],
      "id": "77c1c99c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "id_origem = 'InputID'\n",
        "id_destin = 'TargetID'\n",
        "data = matrix.merge(grid_attributes, left_on =id_destin, right_on='id')"
      ],
      "id": "64cf4036",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Obtaining the neighbors' means for each grid attribute."
      ],
      "id": "c00d0c90"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "NM = data.groupby(id_origem, sort=True).mean()\n",
        "NM.insert(0,'InputID',NM.index)\n",
        "NM['id'] = NM[id_origem]\n",
        "NM.index.names = ['']\n",
        "NM = NM.reset_index()\n",
        "NM = NM[new_grid_rs.iloc[:,:-1].columns]\n",
        "NM"
      ],
      "id": "94347d02",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Obtaining the normalized difference neighbors' means for each grid attribute."
      ],
      "id": "12308d1f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "DNM = (pd.DataFrame(new_grid_rs.iloc[:,:-1]) - pd.DataFrame(NM))/(pd.DataFrame(new_grid_rs.iloc[:,:-1]) + pd.DataFrame(NM))\n",
        "DNM = DNM.fillna(0)\n",
        "DNM['id'] = NM['id']\n",
        "DNM"
      ],
      "id": "5001468d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Renaming the GeoDataFrame columns."
      ],
      "id": "39fe6791"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "DNM.columns = 'DNM_' + DNM.columns\n",
        "NM.columns = 'NM_' + NM.columns"
      ],
      "id": "cc908af9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merging GeoDataFrames: "
      ],
      "id": "2c5d0967"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "DNM = DNM.merge(grid, right_on = 'id', left_on = 'DNM_id', how = 'left')\n",
        "DNM = DNM.drop('id', axis = 1)\n",
        "DNM"
      ],
      "id": "f58cf4cc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating a GeoDataFrame with all attributes:"
      ],
      "id": "f5bfafcf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "final_grid = grid_attributes.iloc[:,:-1].merge(NM, left_on = 'id', right_on = 'NM_id', how = 'left').merge(DNM, left_on = 'id', right_on = 'DNM_id', how = 'left')\n",
        "final_grid = final_grid.drop(['NM_id','DNM_id'], axis = 1)\n",
        "final_grid"
      ],
      "id": "7ea71e57",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saving the final GeoDataFrame:"
      ],
      "id": "c35e504e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "gpd.GeoDataFrame(final_grid).to_file(\"vectors/grid_with_all_attributes.shp\")\n",
        "# final_grid = gpd.read_file(\"vectors/grid_with_all_attributes.shp\")"
      ],
      "id": "6f980a08",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}